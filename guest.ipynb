{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5572, 2)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/SMSSpamCollection', sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split Data into Training and Testing Sets\n",
    "\n",
    "Split the data into 70% training and 30% testing. The `stratify` parameter ensures both sets have the same spam/ham ratio, which is crucial for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3900\n",
      "Test samples: 1672\n",
      "\n",
      "Training distribution:\n",
      "label\n",
      "ham     3377\n",
      "spam     523\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test distribution:\n",
      "label\n",
      "ham     1448\n",
      "spam     224\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nTraining distribution:\\n{train_df['label'].value_counts()}\")\n",
    "print(f\"\\nTest distribution:\\n{test_df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Vectorization\n",
    "\n",
    "`CountVectorizer` converts text documents into a matrix of token counts. It handles:\n",
    "- **Tokenization**: Splitting sentences into words\n",
    "- **Lowercasing**: Normalizing case\n",
    "- **Stop words**: Removing common words (optional)\n",
    "\n",
    "We'll fit it on the training data only to avoid data leakage, then transform both spam and ham separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6860\n",
      "Sample features: ['00' '000' '000pes' '008704050406' '0089' '0121' '01223585334' '02'\n",
      " '0207' '02072069400' '02073162414' '02085076972' '021' '03' '04' '0430'\n",
      " '05' '050703' '0578' '06' '07' '07008009200' '07046744435' '07099833605'\n",
      " '07123456789' '0721072' '07734396839' '07742676969' '07753741225'\n",
      " '07781482378' '07786200117' '078' '07801543489' '07808' '07808247860'\n",
      " '07808726822' '07815296484' '07821230901' '078498' '0789xxxxxxx'\n",
      " '0796xxxxxx' '07xxxxxxxxx' '0800' '08000407165' '08000839402'\n",
      " '08000930705' '08000938767' '08001950382' '08002888812' '08002986030'\n",
      " '08002986906' '08002988890' '08006344447' '0808' '08081263000'\n",
      " '08081560665' '0825' '083' '0844' '08448350055' '08448714184' '0845'\n",
      " '08450542832' '08452810073' '08452810075over18' '0870' '08700469649'\n",
      " '08700621170150p' '08701213186' '08701417012' '08701417012150p'\n",
      " '0870141701216' '087018728737' '0870241182716' '08702840625'\n",
      " '08706091795' '0870737910216yrs' '08707509020' '0870753331018'\n",
      " '08707808226' '08708034412' '08709222922' '08709501522' '0871'\n",
      " '087104711148' '08712101358' '0871212025016' '08712300220'\n",
      " '087123002209am' '08712317606' '08712400200' '08712400602450p'\n",
      " '08712402050' '08712402578' '08712402779' '08712402902' '08712404000'\n",
      " '08712405020' '08712405022' '08712460324']\n"
     ]
    }
   ],
   "source": [
    "# Initialize vectorizer (removes common English stop words)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit on all training data and transform\n",
    "X_train_counts = vectorizer.fit_transform(train_df['message'])\n",
    "\n",
    "# Get feature names (unique words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"Vocabulary size: {len(feature_names)}\")\n",
    "print(f\"Sample features: {feature_names[:100]}\")\n",
    "\n",
    "# Separate spam and ham matrices\n",
    "spam_matrix = vectorizer.transform(train_df[train_df['label'] == 'spam']['message'])\n",
    "ham_matrix = vectorizer.transform(train_df[train_df['label'] == 'ham']['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Class Priors\n",
    "\n",
    "The prior probability is simply the proportion of each class in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam) = 0.1341\n",
      "P(Ham)  = 0.8659\n"
     ]
    }
   ],
   "source": [
    "# Calculate prior probabilities\n",
    "p_spam = len(train_df[train_df['label'] == 'spam']) / len(train_df)\n",
    "p_ham = len(train_df[train_df['label'] == 'ham']) / len(train_df)\n",
    "\n",
    "print(f\"P(Spam) = {p_spam:.4f}\")\n",
    "print(f\"P(Ham)  = {p_ham:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate Word Conditional Probabilities\n",
    "\n",
    "For each word, we calculate:\n",
    "- **Spamicity**: Probability word appears in a spam email\n",
    "- **Hamicity**: Probability word appears in a ham email\n",
    "\n",
    "We use **Laplace smoothing** (add-1 smoothing) to handle unseen words and avoid zero probabilities:\n",
    "```\n",
    "P(word|Spam) = (spam_emails_with_word + 1) / (total_spam_emails + 2)\n",
    "```\n",
    "\n",
    "We count **documents** containing each word, not raw frequency, following the Bernoulli Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities:\n",
      "'password': Spamicity=0.0076, Hamicity=0.0009\n",
      "'website': Spamicity=0.0038, Hamicity=0.0015\n",
      "'free': Spamicity=0.2305, Hamicity=0.0118\n",
      "'hi': Spamicity=0.0248, Hamicity=0.0228\n"
     ]
    }
   ],
   "source": [
    "# Initialize probability dictionaries\n",
    "spamicity = {}\n",
    "hamicity = {}\n",
    "\n",
    "# Calculate for each word in vocabulary\n",
    "for idx, word in enumerate(feature_names):\n",
    "    # Count documents containing the word\n",
    "    spam_docs_with_word = (spam_matrix[:, idx].toarray() > 0).sum()\n",
    "    ham_docs_with_word = (ham_matrix[:, idx].toarray() > 0).sum()\n",
    "    \n",
    "    # Apply Laplace smoothing\n",
    "    spamicity[word] = (spam_docs_with_word + 1) / (spam_matrix.shape[0] + 2)\n",
    "    hamicity[word] = (ham_docs_with_word + 1) / (ham_matrix.shape[0] + 2)\n",
    "\n",
    "print(\"Sample probabilities:\")\n",
    "for word in ['password', 'website', 'free', 'hi'][:4]:\n",
    "    print(f\"'{word}': Spamicity={spamicity[word]:.4f}, Hamicity={hamicity[word]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction Function\n",
    "\n",
    "Our `predict()` function:\n",
    "1. Vectorizes the input email\n",
    "2. Calculates **log probabilities** to prevent numerical underflow\n",
    "3. Multiplies probabilities (adds logs) for all words\n",
    "4. Normalizes to get final spam confidence\n",
    "5. Returns classification and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(email):\n",
    "    \"\"\"\n",
    "    Predict whether an email is spam or ham using manual Naive Bayes\n",
    "    Returns: (prediction, spam_probability)\n",
    "    \"\"\"\n",
    "    # Vectorize the email\n",
    "    email_vector = vectorizer.transform([email])\n",
    "    words_in_email = [feature_names[i] for i in email_vector.indices]\n",
    "    \n",
    "    # Start with log priors\n",
    "    log_prob_spam = np.log(p_spam)\n",
    "    log_prob_ham = np.log(p_ham)\n",
    "    \n",
    "    # Add log conditional probabilities for each word\n",
    "    for word in words_in_email:\n",
    "        # Get spamicity/hamicity with smoothing for unseen words\n",
    "        word_spamicity = spamicity.get(word, 1/(spam_matrix.shape[0] + 2))\n",
    "        word_hamicity = hamicity.get(word, 1/(ham_matrix.shape[0] + 2))\n",
    "        \n",
    "        log_prob_spam += np.log(word_spamicity)\n",
    "        log_prob_ham += np.log(word_hamicity)\n",
    "    \n",
    "    # Convert from log space and normalize\n",
    "    prob_spam = np.exp(log_prob_spam)\n",
    "    prob_ham = np.exp(log_prob_ham)\n",
    "    total = prob_spam + prob_ham\n",
    "    \n",
    "    spam_confidence = prob_spam / total if total > 0 else 0.5\n",
    "    \n",
    "    return 'spam' if spam_confidence >= 0.5 else 'ham', spam_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Evaluation Metrics\n",
    "\n",
    "We'll implement our own evaluation function to calculate:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Confusion Matrix**: TP, TN, FP, FN\n",
    "- **Precision**: True spam / Predicted spam\n",
    "- **Recall**: True spam / Actual spam\n",
    "- **F1-Score**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate classification metrics manually\n",
    "    \"\"\"\n",
    "    # Confusion matrix components\n",
    "    tp = sum(1 for t, p in zip(y_true, y_pred) if t == 'spam' and p == 'spam')\n",
    "    tn = sum(1 for t, p in zip(y_true, y_pred) if t == 'ham' and p == 'ham')\n",
    "    fp = sum(1 for t, p in zip(y_true, y_pred) if t == 'ham' and p == 'spam')\n",
    "    fn = sum(1 for t, p in zip(y_true, y_pred) if t == 'spam' and p == 'ham')\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / len(y_true) if len(y_true) > 0 else 0\n",
    "    \n",
    "    # Spam metrics\n",
    "    precision_spam = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall_spam = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_spam = (2 * precision_spam * recall_spam / (precision_spam + recall_spam) \n",
    "               if (precision_spam + recall_spam) > 0 else 0)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"                Pred Spam  Pred Ham\")\n",
    "    print(f\"Actual Spam     {tp:<10} {fn:<10}\")\n",
    "    print(f\"Actual Ham      {fp:<10} {tn:<10}\")\n",
    "    print(f\"\\nSpam Metrics:\")\n",
    "    print(f\"  Precision: {precision_spam:.4f}\")\n",
    "    print(f\"  Recall:    {recall_spam:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1_spam:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion': {'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn},\n",
    "        'precision': precision_spam,\n",
    "        'recall': recall_spam,\n",
    "        'f1': f1_spam\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Set Evaluation ===\n",
      "Accuracy: 0.8385\n",
      "\n",
      "Confusion Matrix:\n",
      "                Pred Spam  Pred Ham\n",
      "Actual Spam     222        2         \n",
      "Actual Ham      268        1180      \n",
      "\n",
      "Spam Metrics:\n",
      "  Precision: 0.4531\n",
      "  Recall:    0.9911\n",
      "  F1-Score:  0.6218\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "test_predictions = []\n",
    "test_probabilities = []\n",
    "\n",
    "for email in test_df['message']:\n",
    "    pred, prob = predict(email)\n",
    "    test_predictions.append(pred)\n",
    "    test_probabilities.append(prob)\n",
    "\n",
    "# Evaluate results\n",
    "print(\"=== Test Set Evaluation ===\")\n",
    "metrics = evaluate(test_df['label'], test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test on Custom Emails\n",
    "\n",
    "Let's test our classifier on the same emails from your original example to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Custom Email Predictions ===\n",
      "\n",
      "Email: 'renew your password'\n",
      "  Prediction: SPAM\n",
      "  Spam Confidence: 0.5706 (57.06%)\n",
      "\n",
      "Email: 'renew your vows'\n",
      "  Prediction: HAM\n",
      "  Spam Confidence: 0.1341 (13.41%)\n",
      "\n",
      "Email: 'benefits of our account'\n",
      "  Prediction: SPAM\n",
      "  Spam Confidence: 0.9112 (91.12%)\n",
      "\n",
      "Email: 'the importance of physical activity'\n",
      "  Prediction: HAM\n",
      "  Spam Confidence: 0.1341 (13.41%)\n"
     ]
    }
   ],
   "source": [
    "# Your test emails\n",
    "custom_emails = [\n",
    "    'renew your password',\n",
    "    'renew your vows',\n",
    "    'benefits of our account',\n",
    "    'the importance of physical activity'\n",
    "]\n",
    "\n",
    "print(\"=== Custom Email Predictions ===\")\n",
    "for email in custom_emails:\n",
    "    pred, prob = predict(email)\n",
    "    print(f\"\\nEmail: '{email}'\")\n",
    "    print(f\"  Prediction: {pred.upper()}\")\n",
    "    print(f\"  Spam Confidence: {prob:.4f} ({prob*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :TODO Make this code sample simpler and add the formulas on top"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
